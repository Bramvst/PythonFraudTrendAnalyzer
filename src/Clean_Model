import os
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import SMOTE
from sklearn.metrics import classification_report
import joblib

# ==== Paths ====
data_path = os.path.join("Data", "creditcard.csv")
model_dir = "models"
model_path = os.path.join(model_dir, "fraude_random_forest.pkl")
os.makedirs(model_dir, exist_ok=True)

# ==== Load data ====
df = pd.read_csv(data_path)
X = df.drop(columns=["Class"])
y = df["Class"]

# ==== Train/test split ====
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# ==== SMOTE op training set ====
smote = SMOTE(random_state=42)
X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)

# ==== Scale features ====
scaler = StandardScaler()
X_train_sm = scaler.fit_transform(X_train_sm)
X_test_scaled = scaler.transform(X_test)

# ==== Train Random Forest ====
rf_model = RandomForestClassifier(
    n_estimators=100,
    class_weight="balanced",
    random_state=42,
    n_jobs=-1
)
rf_model.fit(X_train_sm, y_train_sm)

# ==== Evaluate ====
y_pred = rf_model.predict(X_test_scaled)
print("Classification report:\n")
print(classification_report(y_test, y_pred, target_names=["No fraud", "Fraud"]))

# ==== Save model & scaler ====
joblib.dump(rf_model, model_path)
joblib.dump(scaler, os.path.join(model_dir, "scaler.pkl"))
print(f"\nModel and scaler saved in '{model_dir}'")
